{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Arthur Fuhrken \n",
    "\n",
    "Nome: Pedro Mahfuz\n",
    "\n",
    "Nome: Rodrigo Furukawa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\osbor\\Documents\\2021.1\\Cdados DP\\Projeto 1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ruffles.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uma criancinha deu um ruffles pra ela</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @favskyliex: üìñ sorteio üìñ\\n\\npara concorrer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_adryelleac @americanascom a√≠ sim, adry! imag...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@b_ruffles eu vo para de estuda tamb√©m</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>assimmm completamente eu arrumando as parede d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Valor\n",
       "0              uma criancinha deu um ruffles pra ela      1\n",
       "1  rt @favskyliex: üìñ sorteio üìñ\\n\\npara concorrer ...      0\n",
       "2  @_adryelleac @americanascom a√≠ sim, adry! imag...      2\n",
       "3             @b_ruffles eu vo para de estuda tamb√©m      0\n",
       "4  assimmm completamente eu arrumando as parede d...      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@vulgo_ruffles amo vc ü•∞ü•∞</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @igoritonobrasil: üèêüíï amor doce üíïüèê\\n#haikyuu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @bonecker_: incr√≠vel que eu taco o fodase p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[9:55 pm, 17/03/2021] alexia: eu comi s√≥ ruffl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hj n√£o foi um bom dia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Valor\n",
       "0                           @vulgo_ruffles amo vc ü•∞ü•∞      0\n",
       "1  rt @igoritonobrasil: üèêüíï amor doce üíïüèê\\n#haikyuu...      0\n",
       "2  rt @bonecker_: incr√≠vel que eu taco o fodase p...      2\n",
       "3  [9:55 pm, 17/03/2021] alexia: eu comi s√≥ ruffl...      1\n",
       "4                              hj n√£o foi um bom dia      0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O nosso produto √© a famosa batata \"Ruffles\", consideramos como tweets relevantes os que falassem do produto de uma maneira pejorativa ou positiva. Consideramos como irrelevantes, os tweets que falavam do produto, mas n√£o agregavam nada a ele. Por fim, consideramos muito irrelevantes os tweets que n√£o faziam qualquer tipo de men√ß√£o ao produto ou que continham conte√∫do completamente desagregado ao valor dele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando classes \"cleanup\", usadas para deixar as strings mais padronizadas.\n",
    "\n",
    "def cleanup_pontuacao(tweets):\n",
    "    p = '[!-.:?;\"\\n\"()''\"\",_%$¬Æ|=‚Äú‚Äù‚Äî/]'\n",
    "    padrao = re.compile(p)\n",
    "    remove_ponto = re.sub(padrao,' ',tweets)\n",
    "    espaco = ' '\n",
    "    padrao = re.compile(espaco)\n",
    "    tweets_espaco = re.sub(padrao, ' ', remove_ponto)\n",
    "    return tweets_espaco\n",
    "    \n",
    "def cleanup_espacos(tweets):    \n",
    "    espacos = ' '\n",
    "    padrao = re.compile(espacos)\n",
    "    remove_espaco = re.sub(padrao,' ', tweets)\n",
    "    return remove_espaco\n",
    "\n",
    "def cleanup_link(tweets):\n",
    "    link = r'http[^\\s]*'\n",
    "    padrao = re.compile(link)\n",
    "    remove_link = re.sub(padrao,'',tweets)\n",
    "    return remove_link\n",
    "\n",
    "trein_str=str()\n",
    "for n in train['Treinamento']:\n",
    "    trein_str+=' '+n\n",
    "\n",
    "\n",
    "\n",
    "trein = trein_str.lower()\n",
    "trein1 = cleanup_pontuacao(trein)\n",
    "trein2 = cleanup_espacos(trein1)\n",
    "trein_limpo = cleanup_link(trein2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando UNICODE emoji para separar os emojis\n",
    "\n",
    "def seleciona_emoji(character):\n",
    "        return character in emoji.UNICODE_EMOJI \n",
    "    \n",
    "def character_tem_emoji(texto):\n",
    "    return ''.join(' ' + char + ' ' if seleciona_emoji(char) else char for char in texto).strip()    \n",
    "\n",
    "trein_f = character_tem_emoji(trein_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ruffles       0.046613\n",
       "de            0.036663\n",
       "e             0.025896\n",
       "que           0.018400\n",
       "a             0.017582\n",
       "                ...   \n",
       "batata‚Ä¶       0.000136\n",
       "espinhando    0.000136\n",
       "deve          0.000136\n",
       "6iwz338win    0.000136\n",
       "matar         0.000136\n",
       "Length: 2186, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando um pd.Series com todas as palavras e suas frequencias relativas\n",
    "\n",
    "palavras = trein_f.split()\n",
    "\n",
    "total = pd.Series(palavras)\n",
    "total.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Muito Irrelevante    0.396\n",
       "Irrelevante          0.330\n",
       "Relevante            0.274\n",
       "Name: Valor, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Valor']=train['Valor'].astype('category')\n",
    "train['Valor'].cat.categories = [\"Muito Irrelevante\",\"Irrelevante\",\"Relevante\"]\n",
    "\n",
    "train['Valor'].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_0 = train['Valor'] == 'Muito Irrelevante'\n",
    "muito_irrelevante = train.loc[filtro_0,:]\n",
    "\n",
    "filtro_1 = train['Valor'] == 'Irrelevante'\n",
    "irrelevante = train.loc[filtro_1,:]\n",
    "\n",
    "filtro_2 = train['Valor'] == 'Relevante'\n",
    "relevante = train.loc[filtro_2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Limpando relevantes da tabela Treinamento com as fun√ß√µes criadas no inicio\n",
    "\n",
    "relevantes_clean=str()\n",
    "for n in relevante['Treinamento']:\n",
    "    relevantes_clean+=' '+n\n",
    "    \n",
    "relevantes = relevantes_clean.lower()\n",
    "relevantes1 = cleanup_pontuacao(relevantes)\n",
    "relevantes2 = cleanup_espacos(relevantes1)\n",
    "relevantes_limpo = cleanup_link(relevantes2)\n",
    "relevantes_emoji = character_tem_emoji(relevantes_limpo)\n",
    "\n",
    "palavras1 = relevantes_emoji.split()\n",
    "total1 = pd.Series(palavras1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando irrelevantes da tabela Treinamento com as fun√ß√µes criadas no inicio\n",
    "\n",
    "irrelevantes_clean=str()\n",
    "for n in irrelevante['Treinamento']:\n",
    "    irrelevantes_clean+=' '+n\n",
    "    \n",
    "irrelevantes = irrelevantes_clean.lower()\n",
    "irrelevantes1 = cleanup_pontuacao(irrelevantes)\n",
    "irrelevantes2 = cleanup_espacos(irrelevantes1)\n",
    "irrelevantes_limpo = cleanup_link(irrelevantes2)\n",
    "irrelevantes_emoji = character_tem_emoji(irrelevantes_limpo)\n",
    "\n",
    "palavras2 = irrelevantes_emoji.split()\n",
    "total2 = pd.Series(palavras2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando m_irrelevantes da tabela Treinamento com as fun√ß√µes criadas no inicio\n",
    "\n",
    "m_irrelevantes_clean=str()\n",
    "for n in muito_irrelevante['Treinamento']:\n",
    "    m_irrelevantes_clean+=' '+n\n",
    "    \n",
    "m_irrelevantes = m_irrelevantes_clean.lower()\n",
    "m_irrelevantes1 = cleanup_pontuacao(m_irrelevantes)\n",
    "m_irrelevantes2 = cleanup_espacos(m_irrelevantes1)\n",
    "m_irrelevantes_limpo = cleanup_link(m_irrelevantes2)\n",
    "m_irrelevantes_emoji = character_tem_emoji(m_irrelevantes_limpo)\n",
    "\n",
    "palavras3 = m_irrelevantes_emoji.split()\n",
    "total3 = pd.Series(palavras3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando lista com palavras limpas relevantes\n",
    "\n",
    "relevantes = []\n",
    "\n",
    "for i in relevante['Treinamento']:\n",
    "    relevantes_clean = i.lower()\n",
    "    relevantes1 = cleanup_pontuacao(relevantes_clean)\n",
    "    relevantes2 = cleanup_espacos(relevantes1)\n",
    "    relevantes_limpo = cleanup_link(relevantes2)\n",
    "    relevantes_emoji = character_tem_emoji(relevantes_limpo)\n",
    "    \n",
    "    for t in relevantes_emoji.split():\n",
    "        relevantes.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando lista com palavras limpas irrelevantes\n",
    "\n",
    "irrelevantes = []\n",
    "\n",
    "for i in irrelevante['Treinamento']:\n",
    "    irrelevantes_clean = i.lower()\n",
    "    irrelevantes1 = cleanup_pontuacao(irrelevantes_clean)\n",
    "    irrelevantes2 = cleanup_espacos(irrelevantes1)\n",
    "    irrelevantes_limpo = cleanup_link(irrelevantes2)\n",
    "    irrelevantes_emoji = character_tem_emoji(irrelevantes_limpo)\n",
    "    \n",
    "    for t in irrelevantes_emoji.split():\n",
    "        irrelevantes.append(t)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando lista com palavras limpas muito irrelevantes\n",
    "\n",
    "m_irrelevantes = []\n",
    "\n",
    "for i in muito_irrelevante['Treinamento']:\n",
    "    m_irrelevantes_clean = i.lower()\n",
    "    m_irrelevantes1 = cleanup_pontuacao(m_irrelevantes_clean)\n",
    "    m_irrelevantes2 = cleanup_espacos(m_irrelevantes1)\n",
    "    m_irrelevantes_limpo = cleanup_link(m_irrelevantes2)\n",
    "    m_irrelevantes_emoji = character_tem_emoji(m_irrelevantes_limpo)\n",
    "    \n",
    "    for t in m_irrelevantes_emoji.split():\n",
    "        m_irrelevantes.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando lista com todas as palavras limpas\n",
    "\n",
    "todas_palavras = []\n",
    "\n",
    "for i in train['Treinamento']:\n",
    "    todas_clean = i.lower()\n",
    "    todas1 = cleanup_pontuacao(todas_clean)\n",
    "    todas2 = cleanup_espacos(todas1)\n",
    "    todas_limpo = cleanup_link(todas2)\n",
    "    todas_emoji = character_tem_emoji(todas_limpo)\n",
    "    \n",
    "    for t in todas_emoji.split():\n",
    "        todas_palavras.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somando palavras de cada categoria\n",
    "\n",
    "rel = total1.value_counts()\n",
    "total_rel = total1.value_counts().sum()\n",
    "\n",
    "irrel = total2.value_counts()\n",
    "total_irrel = total2.value_counts().sum()\n",
    "\n",
    "m_irrel = total3.value_counts()\n",
    "total_m_irrel = total3.value_counts().sum()\n",
    "\n",
    "total_palavras = total.value_counts()\n",
    "total_palavras_soma = total.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2186"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Smoothing para cada categoria\n",
    "\n",
    "A = len(total_palavras)\n",
    "a = 1\n",
    "\n",
    "smooth_0_rel = rel + a\n",
    "smooth_1_rel = total_rel + A\n",
    "\n",
    "smooth_0_irrel = irrel + a\n",
    "smooth_1_irrel = total_irrel + A\n",
    "\n",
    "smooth_0_m_irrel = m_irrel + a\n",
    "smooth_1_m_irrel = total_m_irrel + A\n",
    "\n",
    "len(total_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(palavra|\"Categoria\")\n",
    "\n",
    "P_pal_rel = smooth_0_rel/smooth_1_rel\n",
    "P_pal_irrel = smooth_0_irrel/smooth_1_irrel\n",
    "P_pal_m_irrel = smooth_0_m_irrel/smooth_1_m_irrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_relevantes = []\n",
    "p_irrelevantes = []\n",
    "p_m_irrelevantes = []\n",
    "\n",
    "for i in relevantes:\n",
    "    p_t = 0\n",
    "    if i in P_pal_rel:\n",
    "        p_t+=log(P_pal_rel[i])\n",
    "    else:\n",
    "        p_t+=log(a/total_rel+A)\n",
    "    p_relevantes.append(p_t)\n",
    "\n",
    "\n",
    "for i in irrelevantes:\n",
    "    p_t = 0\n",
    "    if i in P_pal_irrel:\n",
    "        p_t+=log(P_pal_irrel[i])\n",
    "    else:\n",
    "        p_t+=log(a/total_irrel+A)\n",
    "    p_irrelevantes.append(p_t)\n",
    "    \n",
    "\n",
    "for i in m_irrelevantes:\n",
    "    p_t = 0\n",
    "    if i in P_pal_m_irrel:\n",
    "        p_t+=log(P_pal_m_irrel[i])\n",
    "    else:\n",
    "        p_t+=log(a/total_m_irrel+A)\n",
    "    p_m_irrelevantes.append(p_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@': 'Muito irrelevante',\n",
       " '@americanascom': 'Irrelevante',\n",
       " 'a√≠': 'Muito irrelevante',\n",
       " 'sim': 'Relevante',\n",
       " 'comprar': 'Irrelevante',\n",
       " 'uma': 'Relevante',\n",
       " 'ruffles': 'Irrelevante',\n",
       " 'tira': 'Irrelevante',\n",
       " 'onda': 'Irrelevante',\n",
       " 'por': 'Relevante',\n",
       " 'apenas': 'Muito irrelevante',\n",
       " '99': 'Irrelevante',\n",
       " 'centavos': 'Relevante',\n",
       " 'isso': 'Muito irrelevante',\n",
       " '√©': 'Relevante',\n",
       " 'coisa': 'Relevante',\n",
       " 'de': 'Relevante',\n",
       " 'outro': 'Relevante',\n",
       " 'mundo': 'Muito irrelevante',\n",
       " 'üåÄ': 'Muito irrelevante',\n",
       " 'o': 'Muito irrelevante',\n",
       " 'eu': 'Muito irrelevante',\n",
       " 'comi': 'Irrelevante',\n",
       " 's√≥': 'Relevante',\n",
       " 'um': 'Irrelevante',\n",
       " 'pacote': 'Relevante',\n",
       " 'batata': 'Relevante',\n",
       " 'e': 'Irrelevante',\n",
       " 'minha': 'Irrelevante',\n",
       " 'foi': 'Irrelevante',\n",
       " 'pra': 'Muito irrelevante',\n",
       " 'quero': 'Relevante',\n",
       " 'me': 'Relevante',\n",
       " 'coca': 'Relevante',\n",
       " 'bem': 'Muito irrelevante',\n",
       " 'mim': 'Relevante',\n",
       " 'em': 'Relevante',\n",
       " 'que': 'Relevante',\n",
       " 'salgadinho': 'Relevante',\n",
       " 'da': 'Irrelevante',\n",
       " 'ou': 'Irrelevante',\n",
       " 'sensa√ß√µes': 'Irrelevante',\n",
       " 't': 'Muito irrelevante',\n",
       " 'co': 'Irrelevante',\n",
       " 'do': 'Relevante',\n",
       " 'nada': 'Relevante',\n",
       " 'comer': 'Relevante',\n",
       " '@euotrouxa': 'Relevante',\n",
       " 'cheetos': 'Irrelevante',\n",
       " 'nossa': 'Relevante',\n",
       " 'muito': 'Relevante',\n",
       " 'bom': 'Muito irrelevante',\n",
       " 'lays': 'Relevante',\n",
       " 'lata': 'Irrelevante',\n",
       " 'r': 'Relevante',\n",
       " 'com': 'Irrelevante',\n",
       " '10': 'Irrelevante',\n",
       " 'frete': 'Muito irrelevante',\n",
       " 'gr√°tis': 'Irrelevante',\n",
       " 'mais': 'Relevante',\n",
       " 'vai': 'Muito irrelevante',\n",
       " 'a': 'Irrelevante',\n",
       " 'ta': 'Muito irrelevante',\n",
       " 'agora': 'Relevante',\n",
       " 'queria': 'Relevante',\n",
       " 'mas': 'Relevante',\n",
       " 'nao': 'Muito irrelevante',\n",
       " 'saco': 'Relevante',\n",
       " 'est√°': 'Relevante',\n",
       " 'umas': 'Relevante',\n",
       " 'quem': 'Muito irrelevante',\n",
       " 'manda': 'Irrelevante',\n",
       " '1': 'Relevante',\n",
       " 'acho': 'Relevante',\n",
       " 'sabor': 'Relevante',\n",
       " 'no': 'Irrelevante',\n",
       " 'tipo': 'Irrelevante',\n",
       " 'n√£o': 'Irrelevante',\n",
       " 'eh': 'Muito irrelevante',\n",
       " 'melhor': 'Relevante',\n",
       " 'pq': 'Muito irrelevante',\n",
       " 'queijo': 'Relevante',\n",
       " 'pringles': 'Irrelevante',\n",
       " 'resto': 'Relevante',\n",
       " 'q': 'Relevante',\n",
       " 'vc': 'Muito irrelevante',\n",
       " 'nunca': 'Muito irrelevante',\n",
       " 'algo': 'Muito irrelevante',\n",
       " 'gente': 'Muito irrelevante',\n",
       " 'saiu': 'Relevante',\n",
       " 'faz': 'Irrelevante',\n",
       " 'era': 'Irrelevante',\n",
       " 'fui': 'Muito irrelevante',\n",
       " '@ruffles': 'Muito irrelevante',\n",
       " 'oficial': 'Muito irrelevante',\n",
       " 'saudade': 'Irrelevante',\n",
       " 'olha': 'Relevante',\n",
       " 'nas': 'Irrelevante',\n",
       " 'favor': 'Irrelevante',\n",
       " 'ele': 'Muito irrelevante',\n",
       " 'fazer': 'Irrelevante',\n",
       " 'toda': 'Muito irrelevante',\n",
       " 'vez': 'Muito irrelevante',\n",
       " 'como': 'Relevante',\n",
       " 'ü§§': 'Muito irrelevante',\n",
       " 'tbm': 'Muito irrelevante',\n",
       " 'rt': 'Muito irrelevante',\n",
       " 'as': 'Muito irrelevante',\n",
       " 'melhores': 'Relevante',\n",
       " 'amp': 'Relevante',\n",
       " 'ruim': 'Relevante',\n",
       " 'poxa': 'Relevante',\n",
       " 'ü•∫': 'Muito irrelevante',\n",
       " 't√¥': 'Muito irrelevante',\n",
       " 'aqui': 'Muito irrelevante',\n",
       " 'comprei': 'Irrelevante',\n",
       " 'esse': 'Muito irrelevante',\n",
       " 'comendo': 'Irrelevante',\n",
       " 'na': 'Irrelevante',\n",
       " 'jogar': 'Irrelevante',\n",
       " 'dinheiro': 'Relevante',\n",
       " 'fandangos': 'Irrelevante',\n",
       " 'se': 'Irrelevante',\n",
       " 'ainda': 'Irrelevante',\n",
       " 'tem': 'Relevante',\n",
       " 'conta': 'Muito irrelevante',\n",
       " 'pelo': 'Relevante',\n",
       " 'menos': 'Relevante',\n",
       " 'doritos': 'Irrelevante',\n",
       " 'para': 'Muito irrelevante',\n",
       " 'os': 'Muito irrelevante',\n",
       " 'nos': 'Muito irrelevante',\n",
       " 'anos': 'Irrelevante',\n",
       " '90': 'Relevante',\n",
       " 'achei': 'Irrelevante',\n",
       " 'sei': 'Relevante',\n",
       " 'ent√£o': 'Muito irrelevante',\n",
       " 'meu': 'Muito irrelevante',\n",
       " 'j√°': 'Muito irrelevante',\n",
       " 'quando': 'Irrelevante',\n",
       " 'üò≠': 'Muito irrelevante',\n",
       " 'vida': 'Irrelevante',\n",
       " 'dia': 'Muito irrelevante',\n",
       " 'virou': 'Relevante',\n",
       " 'p': 'Relevante',\n",
       " 'sem': 'Muito irrelevante',\n",
       " 'deu': 'Muito irrelevante',\n",
       " 'essa': 'Irrelevante',\n",
       " 'pqp': 'Relevante',\n",
       " 'to': 'Irrelevante',\n",
       " 'dias': 'Irrelevante',\n",
       " 'noite': 'Irrelevante',\n",
       " 'come': 'Irrelevante',\n",
       " 'onde': 'Muito irrelevante',\n",
       " 'sentindo': 'Relevante',\n",
       " 'poder': 'Relevante',\n",
       " 'ser': 'Muito irrelevante',\n",
       " 'gt': 'Relevante',\n",
       " 'qualquer': 'Irrelevante',\n",
       " 'm√£e': 'Irrelevante',\n",
       " 'ela': 'Irrelevante',\n",
       " 't√£o': 'Irrelevante',\n",
       " 'mesmo': 'Muito irrelevante',\n",
       " 'ai': 'Muito irrelevante',\n",
       " 'tao': 'Relevante',\n",
       " 'so': 'Irrelevante',\n",
       " 'depois': 'Muito irrelevante',\n",
       " 'gosta': 'Muito irrelevante',\n",
       " 'n√©': 'Irrelevante',\n",
       " 'azul': 'Irrelevante',\n",
       " 'nova': 'Irrelevante',\n",
       " 't√°': 'Muito irrelevante',\n",
       " 'kkkkkkk': 'Relevante',\n",
       " 'tirar': 'Relevante',\n",
       " 'ver': 'Muito irrelevante',\n",
       " 'at√©': 'Muito irrelevante',\n",
       " 'pouco': 'Irrelevante',\n",
       " 'vou': 'Muito irrelevante',\n",
       " 'simplesmente': 'Relevante',\n",
       " 'parar': 'Relevante',\n",
       " 'Ô∏è': 'Muito irrelevante',\n",
       " '@itscopys': 'Relevante',\n",
       " 'n': 'Irrelevante',\n",
       " 'nesse': 'Muito irrelevante',\n",
       " 'loja': 'Muito irrelevante',\n",
       " 'bis': 'Muito irrelevante',\n",
       " 'kkkkkk': 'Irrelevante',\n",
       " 'sua': 'Irrelevante',\n",
       " 'tinha': 'Irrelevante',\n",
       " 'mesma': 'Relevante',\n",
       " 'voc√™': 'Irrelevante',\n",
       " 'ü§°': 'Irrelevante',\n",
       " 'semana': 'Muito irrelevante',\n",
       " 'crian√ßa': 'Relevante',\n",
       " 'quer': 'Relevante',\n",
       " 'tava': 'Muito irrelevante',\n",
       " 'indo': 'Relevante',\n",
       " '‚ù§': 'Muito irrelevante'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando dicion√°rios com keys = palavra, e values = probabilidade, de cada categoria\n",
    "\n",
    "d_relevante = {}\n",
    "for i in range(len(relevantes)):\n",
    "    d_relevante[relevantes[i]] = p_relevantes[i]\n",
    "\n",
    "\n",
    "d_irrelevante = {}\n",
    "for i in range(len(irrelevantes)):\n",
    "    d_irrelevante[irrelevantes[i]] = p_irrelevantes[i]\n",
    "\n",
    "\n",
    "d_m_irrelevante = {}\n",
    "for i in range(len(m_irrelevantes)):\n",
    "    d_m_irrelevante[m_irrelevantes[i]] = p_m_irrelevantes[i]\n",
    "    \n",
    "\n",
    "# Criando c√≥digo que identifica se uma palavra de ser considerada Relevante, Irrelevante ou Muito irrelevante     \n",
    "    \n",
    "d_final = {}\n",
    "\n",
    "for k_r,v_r in d_relevante.items():\n",
    "    for k_i,v_i in d_irrelevante.items():\n",
    "        if k_r == k_i:\n",
    "            for k_m,v_m in d_m_irrelevante.items():\n",
    "                if k_r == k_m:\n",
    "                    if (v_r > v_i) and (v_r > v_m):\n",
    "                        d_final[k_r] = \"Relevante\"\n",
    "                    elif (v_i > v_r) and (v_i > v_m):\n",
    "                        d_final[k_i] = \"Irrelevante\"\n",
    "                    elif (v_m > v_r) and (v_m > v_i):\n",
    "                        d_final[k_m] = \"Muito irrelevante\"\n",
    "\n",
    "            if (k_r != k_i) and (k_r != k_m) and k_r not in d_final:\n",
    "                d_final[k_r] = 'Relevante'\n",
    "\n",
    "            elif (k_r != k_i) and (k_r != k_m) and k_i not in d_final:\n",
    "                d_final[k_i] = 'Irrelevante'\n",
    "\n",
    "            elif (k_r != k_i) and (k_r != k_m) and k_m not in d_final:\n",
    "                d_final[k_m] = 'Muito irrelevante'\n",
    "d_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Muito irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Muito Irrelevante</th>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.362069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Naive Bayes        Irrelevante  Muito irrelevante  Relevante\n",
       "Valor                                                       \n",
       "Muito Irrelevante     0.323529           0.352941   0.323529\n",
       "Irrelevante           0.305556           0.333333   0.361111\n",
       "Relevante             0.344828           0.293103   0.362069"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_total ={}\n",
    "\n",
    "for i in todas_palavras:\n",
    "    for k_f,v_f in d_final.items():\n",
    "        if k_f == i:\n",
    "            d_total[i] = v_f\n",
    "            \n",
    "lista_final = []\n",
    "\n",
    "for i in d_total.values():\n",
    "    lista_final.append(i)\n",
    "    \n",
    "Naive_Bayes= pd.Series(lista_final)\n",
    "train['Naive Bayes'] = Naive_Bayes \n",
    "pd.crosstab(train['Valor'], train['Naive Bayes'], normalize = 'index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
